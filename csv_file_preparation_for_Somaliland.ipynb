{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEP-OnSSET GIS-Extraction Notebook for Somaliland\n",
    "\n",
    "This is the GEP-OnSSET GIS extraction notebook. This is supposed to act as an alternative to the QGIS plugins available [here](https://github.com/global-electrification-platform/Cluster-based_extraction_OnSSET/tree/master/Plugin). \n",
    "\n",
    "The main purpose of this notebook is to facilitate the change of single datasets without running through the entire plugin. Using this notebook the user will be able to change however many datasets needed.\n",
    "\n",
    "In order to run an OnSSET analysis the following datasets are needed:\n",
    "* Land Cover\n",
    "* Elevation \n",
    "* Slope\n",
    "* Global horizontal irradiation\n",
    "* Travel time\n",
    "* Wind velocity\n",
    "* Clusters **(these clusters should include: The name of the study area, the amount of nighttime lights, population, population living in areas with nighttime light and an ID column)**. The clusters can be downloaded from [Energydata.info](https://energydata.info/) or generated directly using the [following plugin](https://github.com/global-electrification-platform/Clustering)\n",
    "\n",
    "In addition to this there are also some optional datasets that can be used in the analysis:\n",
    "* Custom Demand - A layer that can be created by the users themselves. For the first round of GEP the methodlogy described [here](https://www.mdpi.com/1996-1073/12/7/1395) has been used.\n",
    "* Substations\n",
    "* Transformers\n",
    "* ESPs (existing mini-grids)\n",
    "* Adm0 & Adm1 boundary layers\n",
    "* Mini/Small hydro\n",
    "* Existing and planned HV-lines\n",
    "* Existing and planned MV-lines \n",
    "* Road network\n",
    "\n",
    "Below instructions for each cell follows. The cells marked with **(Mandatory)** in the title have to be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1 - Importing necessary packages (Mandatory)\n",
    "\n",
    "Packages to be used are imported from the funcs.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexl\\Dropbox\\Self-employment\\WBG\\Work\\SEAP\\Somaliland\\Work\\Somaliland_Model\\Input_file_extraction\\funcs.ipynb:372: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  \"    def vector_overlap(vec, settlementfile, column_name):\\n\",\n",
      "C:\\Users\\alexl\\Dropbox\\Self-employment\\WBG\\Work\\SEAP\\Somaliland\\Work\\Somaliland_Model\\Input_file_extraction\\funcs.ipynb:374: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  \"        a = gpd.sjoin(settlementfile, vec, op = 'intersects')\\n\",\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.funcs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2 - Setting the target coordinate system (Mandatory)\n",
    "\n",
    "When calculating distances it is important to choose a coordinate system that represents distances correctly in your area of interst. The coordinate system that is given below is the World Mercator, these coordinate system works well for Sub Saharan Africa but the distortions get larger as you move away from the equator.\n",
    "\n",
    "In order to select your own coordinate system go to [epsg.io](http://epsg.io/) and type in your area of interest, this will give you a list of coordinate systems to choose from. Once you have selected your coordinate system replace the numbers below with the numbers from your coordinate system **(keep the \"EPSG\" part)**.\n",
    "\n",
    "**NOTE** When selecting your coordinate system make sure that you select a system with the unit of meters, this is indicated for all systems on [epsg.io](http://epsg.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = 'EPSG:32638'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3 - Select the workspace and the administrative boundaries (Mandatory)\n",
    "\n",
    "Define the workspace. The output layers will populate this folder. It is highly recommended to select an empty folder as your workspace.\n",
    "\n",
    "For the administrative boundaries you will have to select an **Polygon** layer represeting your area of interest.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messagebox.showinfo('OnSSET extraction', 'Output folder')\n",
    "workspace = filedialog.askdirectory()\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the admin boundaries')\n",
    "admin = gpd.read_file(filedialog.askopenfilename(filetypes = ((\"shapefile\",\"*.shp\"),(\"all files\",\"*.*\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4 - Select the population clusters (Mandatory)\n",
    "\n",
    "Select the clusters to be used in the analysis\n",
    "\n",
    "Please also idicate which column is representing the population data as this will be used later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6123ef387f74c389ce04cb27e17b9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Population:', options=('fid', 'id', 'Country', 'NightLight', 'Buildings', 'Pop', 'Area',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messagebox.showinfo('OnSSET', 'Select the clusters')\n",
    "clusters = gpd.read_file(filedialog.askopenfilename(filetypes = ((\"shapefile\",\"*.shp\"),(\"all files\",\"*.*\"))))\n",
    "    \n",
    "popunit = widgets.Dropdown(options=clusters.head(),\n",
    "    value=None,\n",
    "    description='Population:',\n",
    "    disabled=False)\n",
    "display(popunit)\n",
    "x = popunit.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5 - Select the Population distribution layer (Raster layer)\n",
    "\n",
    "This function will calculate the no of population grid cells in each cluster. It is recommended that you use the population layer that was also used in the generation of clusters. It can be for example the WorldPop (PeanutButter) 100m layer or the resampled (100m) HRSL.\n",
    "\n",
    "In the case of Somaliland, we suggest using the WorldPop 100 raster layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 15:24:55.810154\n"
     ]
    }
   ],
   "source": [
    "clusters = processing_raster(\"ClusterCells\",\"count\",clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6 - Select the building density layer (Raster layer)\n",
    "\n",
    "This function compliments the previous step by estimating the \"Core Cells\" in each cluster. By core cells we mean cells that have at least 10 buildings. This layer is provided by [WorldPop](https://apps.worldpop.org/peanutButter/) as \"Source layer\" download. \n",
    "\n",
    "Before using here, make sure you process it in Qgis (or similar). After you import the raster layer in Qgis, open Raster >> Raster calculator and type the following expression: Raster/(Raster>=10), where Raster is the building density. Once done, you may save the layer with your preferred name and use it in this function.\n",
    "\n",
    "**Note!** The number of 10 buildings is arbitrary and can be customized as per need. This is the number used for the Somaliland model, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 15:54:17.682561\n"
     ]
    }
   ],
   "source": [
    "clusters = processing_raster(\"CoreCells\",\"count\",clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7 - Select the Land Cover map (Raster map)\n",
    "\n",
    "**If your settlement data already includes land cover data, skip to cell 8. Note however that this dataset is mandatory to run the OnSSET analysis**\n",
    "\n",
    "Select the land cover map that you wish to use in your analysis. This cell will extract the land cover values in your raster map to your clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = processing_raster(\"landcover\",\"majority\",clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8 - Select the Elevation map (Raster map)\n",
    "\n",
    "**If your settlement data already includes elevation and slope data, skip to cell 9. Note however that this dataset is mandatory to run the OnSSET analysis**\n",
    "\n",
    "Select the elevation map that you wish to use in your analysis. This cell will extract the elevation values in your raster map to your clusters. This cell will also generate the a map for the terrain slope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 15:00:41.701402\n"
     ]
    }
   ],
   "source": [
    "clusters = processing_elevation_and_slope(\"elevation\",\"mean\",clusters, workspace,crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9 - Select the Global Horizontal Irradiation (GHI) map (Raster map)\n",
    "\n",
    "**If your settlement data already includes GHI data, skip to cell 10. Note however that this dataset is mandatory to run the OnSSET analysis**\n",
    "\n",
    "Select the ghi map that you wish to use in your analysis. This cell will extract the ghi values in your raster map to your clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 15:12:12.725901\n"
     ]
    }
   ],
   "source": [
    "clusters = processing_raster(\"ghi\",\"mean\",clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cell 10 - Select the Travel Time map (Raster map)\n",
    " \n",
    "**If your settlement data already includes travel time data, skip to cell 11. Note however that this dataset is mandatory to run the OnSSET analysis**\n",
    "\n",
    "Select the travel time map that you wish to use in your analysis. This cell will extract the travel time values in your raster map to your clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 15:21:54.118360\n"
     ]
    }
   ],
   "source": [
    "clusters = processing_raster(\"traveltime\",\"mean\",clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11 - Select the Wind Velocity map (Raster map)\n",
    "\n",
    "**If your settlement data already includes wind velocity data, skip to cell 12. Note however that this dataset is mandatory to run the OnSSET analysis**\n",
    "\n",
    "Select the wind velocity map that you wish to use in your analysis. This cell will extract the wind velocity values in your raster map to your clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 15:30:10.486267\n"
     ]
    }
   ],
   "source": [
    "clusters = processing_raster(\"wind\",\"mean\",clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12 - Select the Custom Demand map (Raster map) (optional dataset)\n",
    "\n",
    "Select the custom demand map that you wish to use in your analysis. This is an optional dataset. \n",
    "\n",
    "This cell will extract the custom demand values in your raster map to your clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 15:38:58.896886\n"
     ]
    }
   ],
   "source": [
    "clusters = processing_raster(\"customdemand\",\"mean\",clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13 - Finalizing the raster data\n",
    "\n",
    "\n",
    "Saving the clusters with extracted rasters.\n",
    "\n",
    "**NOTE** You have to run this cell if you ran any of the cells 5 through 12. If you did not run any of the mentioned cells skip to cell 14.\n",
    "\n",
    "**NOTE** In case you get an Driver Error for reading the geojson file into a geodataframe, this might be cause due to attribution of \"inf\" or \"-inf\" value in one of the attributes. This is related to the way python handles json (see fix [here](https://stackoverflow.com/questions/17503981/is-there-a-way-to-override-pythons-json-handler)). An \"easy\" fix is that you import the geojson into Qgis and replace the erroneous value(s) manually. This is not ideal but it will do the job. In that case, save the updated geojson file and use the second (commented) line below to import into a geodataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 17:40:23.026885\n"
     ]
    }
   ],
   "source": [
    "clusters = finalizing_rasters(workspace, clusters, crs)\n",
    "#clusters = gpd.read_file(workspace + r'\\placeholder.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 14 - Preparing to run the vector data\n",
    "\n",
    "**If you are planning on extracting any vector data (substations, transformers, hydro, MV-lines, HV-lines or roads) run this cell**. \n",
    "\n",
    "This cell reprojects the settlements to the coordinate system you specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 17:40:45.789396\n"
     ]
    }
   ],
   "source": [
    "clusters = preparing_for_vectors(workspace, clusters, crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 15 - Substations (Vector point layer)\n",
    "\n",
    "**If you do not have substations or wish to keep the ones already in your settlement file, skip to cell 16.**\n",
    "\n",
    "Determines the distances between each settlement point to the closest substation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = processing_points(\"Substation\", admin, crs, workspace, clusters, mg_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 16 - Existing high voltage lines (Vector line layer)\n",
    "\n",
    "**If you do not have existing high voltage lines or wish to keep the ones already in your settlement file, skip to cell 17.**\n",
    "\n",
    "Determines the distances between each settlement point to the closest existing high voltage line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = processing_lines(\"Existing_HV\", admin, crs, workspace, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 17 - Planned high voltage lines (Vector line layer)\n",
    "\n",
    "**If you do not have planned high voltage lines or wish to keep the ones already in your settlement file, skip to cell 18.**\n",
    "\n",
    "Determines the distances between each settlement point to the closest planned high voltage line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 15:46:30.600139\n"
     ]
    }
   ],
   "source": [
    "clusters = processing_lines(\"Planned_HV\", admin, crs, workspace, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 18 - Existing medium voltage lines (Vector line layer)\n",
    "\n",
    "**If you do not have existing medium voltage lines or wish to keep the ones already in your settlement file, skip to cell 19.**\n",
    "\n",
    "Determines the distances between each settlement point to the closest existing medium voltage line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = processing_lines(\"Existing_MV\", admin, crs, workspace, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 19 - Planned medium voltage lines (Vector line layer)\n",
    "\n",
    "**If you do not have planned medium voltage lines or wish to keep the ones already in your settlement file, skip to cell 20.**\n",
    "\n",
    "Determines the distances between each settlement point to the closest planned medium voltage line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = processing_lines(\"Planned_MV\", admin, crs, workspace, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 20 - Roads (Vector line layer)\n",
    "\n",
    "**If you do not have roads or wish to keep the ones already in your settlement file, skip to cell 21.**\n",
    "\n",
    "Determines the distances between each settlement point to the closest road. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 16:50:50.684918\n"
     ]
    }
   ],
   "source": [
    "clusters = processing_lines(\"Roads\", admin, crs, workspace, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 21 - Transformers (Vector point layer)\n",
    "\n",
    "**If you do not have transformers or wish to keep the ones in the already in the settlement file, skip to cell 22** \n",
    "\n",
    "Determines the distances between each settlement point to the closest transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = processing_points(\"Transformer\", admin, crs, workspace, clusters, mg_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 22 and 23 - Selecting and processing hydro points (Vector point layer)\n",
    "\n",
    "**If you do not have new hydro power points skip to next step\n",
    "\n",
    "**In Cell 22** Select the hydro point layer you wish to use. It is important to have a column representing the power output for each hydro point in your dataset. After selecting the column you will also have to select the unit (W, kW or MW). \n",
    "\n",
    "**In Cell 23** When everything is selected in cell 22, run cell 23 in order to determine the distance to the closest hydro point for each settlement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d72ed3d39da4186a5a719b560f9a3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Hydropower:', options=('fid', 'OBJECTID', 'river_ID', 'elev', 'head', 'discharge_', 'powâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d7af7dd6d140ec8966ba66dd62f77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Unit:', options=('W', 'kW', 'MW'), value='W')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messagebox.showinfo('OnSSET', 'Select the Hydropower map')\n",
    "hydro=gpd.read_file(filedialog.askopenfilename(title = \"Select Hydro map\", filetypes = ((\"shapefile\",\"*.shp\"),(\"all files\",\"*.*\"))))\n",
    "\n",
    "hydropower = widgets.Dropdown(options=hydro.head(),\n",
    "    value=None,\n",
    "    description='Hydropower:',\n",
    "    disabled=False)\n",
    "\n",
    "display(hydropower)\n",
    "      \n",
    "hydrounit = widgets.Dropdown(options=['W', 'kW', 'MW'],\n",
    "    value='W',\n",
    "    description='Unit:',\n",
    "    disabled=False)\n",
    "\n",
    "display(hydrounit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 16:37:57.674632\n"
     ]
    }
   ],
   "source": [
    "clusters = processing_hydro(admin, crs, workspace, clusters, hydro, hydropower.value, hydrounit.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 24 - Selecting and processing Existing ESP (mini-grid) data (Vector point layer)\n",
    "\n",
    "This function extracts the nearest ESP to each clusters and assigns key characteristics (e.g. name, MV network status, type).\n",
    "\n",
    "**If you do not have new hydro power points skip to next step** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-10 13:12:39.361427\n"
     ]
    }
   ],
   "source": [
    "clusters = processing_points(\"Existing_ESP_\", admin, crs, workspace, clusters, mg_filter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 25 - Extracting admin 1 name to clusters (Vector polygon layer)\n",
    "\n",
    "This function extracts the admin level 1 name to each cluster based on spatial overlay. \n",
    "\n",
    "**Please do provide the right column name (e.g. \"adm1_name\") in the function below, as it appears on the GIS layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = get_admin1_name(clusters, \"adm1_name\", crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 26 - Getting IDP and refugee camps status in clusters (Vector polygon layer)\n",
    "\n",
    "This function extracts the existence of IDP or Refugee Camps to cluster based on spatial overlay. \n",
    "\n",
    "**Please do provide the right column name (e.g. \"name\") in the function below, as it appears on the GIS layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = get_IDPs_RefugeeCamps_status(clusters, \"name\", crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 27 - Getting No of buildings per cluster (Vector polygon layer)\n",
    "\n",
    "This function extracts the number of buildings within each cluster based on spatial overlay. \n",
    "\n",
    "**The input layer MUST BE a vector polygon layer in WGS 84**\n",
    "\n",
    "**Please do provide the desired column name (e.g. \"build_count\") as you want it to appear in the result file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = get_buildings_in_clusters(clusters, \"build_count\", crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 28 - Getting No of water points per cluster (Vector polygon layer)\n",
    "\n",
    "This function extracts the number of water points within each cluster based on spatial overlay. \n",
    "\n",
    "**The input layer MUST BE a vector points layer in WGS 84**\n",
    "\n",
    "**Please do provide the desired column name (e.g. \"waterpoint_count\") as you want it to appear in the result file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = get_waterpoints_in_clusters(clusters, \"waterpoints_count\", crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 29 - Preparing prioritization filter columns\n",
    "\n",
    "This function created the additional binary columns used for vizualization purposes on the Explorer. You may need to customize the names as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = create_prio_columns(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 28 - Conditioning & Export (Mandatory)\n",
    "\n",
    "This is the final cell in the extraction. This cell has to be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 16:41:41.939261\n"
     ]
    }
   ],
   "source": [
    "clusters = conditioning(clusters, workspace, popunit.value)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
